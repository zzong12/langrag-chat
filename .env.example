# LLM Configuration
# Base URL for OpenAI-compatible API
LLM_API_BASE_URL=https://api.openai.com/v1
# Model name to use
LLM_MODEL_NAME=gpt-3.5-turbo
# API key for LLM service
LLM_API_KEY=your-api-key-here

# Pinecone Configuration
# Pinecone API key
PINECONE_API_KEY=your-pinecone-api-key
# Pinecone environment/region (e.g., us-east-1, us-west-2)
PINECONE_ENVIRONMENT=us-east-1
# Name of the Pinecone index
PINECONE_INDEX_NAME=rag-index

# Application Configuration
# Directory for uploaded documents
UPLOAD_DIR=./uploads
# Maximum file size in bytes (default: 10MB)
MAX_FILE_SIZE=10485760
# Chunk size for text splitting
CHUNK_SIZE=1000
# Overlap between chunks
CHUNK_OVERLAP=200
# Number of top results to retrieve for RAG
TOP_K_RESULTS=4

# Server Configuration
# Host to bind the server
HOST=0.0.0.0
# Port to run the server
PORT=8000

# Deployment Configuration (for deploy.sh)
# Docker registry URL
DEPLOY_REGISTRY=registry.example.com
# Docker image name (namespace/image)
DEPLOY_IMAGE_NAME=namespace/langrag
# Docker image tag
DEPLOY_IMAGE_TAG=0.0.1
# Remote server SSH connection (user@host)
DEPLOY_REMOTE_HOST=user@example.com
# Remote deployment directory
DEPLOY_REMOTE_DIR=/data/projects/langrag
# Remote service port
DEPLOY_REMOTE_PORT=30006
# Remote server IP address
DEPLOY_REMOTE_IP=1.2.3.4

# Test Configuration (for test_deployment.sh)
# Remote server host or IP for testing
TEST_REMOTE_HOST=example.com
# Remote service port for testing
TEST_REMOTE_PORT=30006
